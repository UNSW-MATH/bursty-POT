---
title: "Peaks Over Threshold for Bursty Time Series"
# titlerunning: "CTRE: POT for Bursty Time Series"
thanks: |
    Peter Straka was supported by the 
    Discovery Early Career Research Award DE160101147 on the Project 
    "Predicting Extremes when Events Occur in Bursts" by the Australian
    Research Council.
    Katharina Hees was supported by 
    the DAAD co-financed by the German Federal Ministry of Education and 
    Research (BMBF). 
   
authors: 
- name: "Katharina Hees"
  address: University of Dortmund
  email: hees@statistik.uni-dortmund.de
  
- name: "Smarak Nayak"
  address: National Australia Bank
  email: smarak.nayak@nab.com.au
  
- name: "Peter Straka*"
  address: UNSW Sydney
  email: p.straka@unsw.edu.au 
  
authorrunning: K. Hees, S. Nayak & P. Straka

keywords:
- heavy tails
- renewal process
- extreme value theory
- peaks over threshold

abstract: |
  In many complex systems studied in statistical physics, 
  inter-arrival times between events such as solar flares, trades and 
  neuron voltages follow a heavy-tailed 
  distribution. The set of event times is fractal-like, being dense in some 
  time windows and empty in others, a phenomenon which has been dubbed 
  "bursty". 
  
  This article generalizes the Peaks Over Threshold (POT) model to the setting 
  where inter-event times are heavy-tailed. For high thresholds and 
  infinite-mean waiting times, we show that the times between threshold 
  crossings are Mittag-Leffler distributed, and thus form a "fractional 
  Poisson Process" which generalizes the standard Poisson Process.
  We provide graphical means of estimating model parameters and assessing 
  model fit. Along the way, we apply our inference method to a real-world
  bursty time series, and 
  show how the memory of the Mittag-Leffler distribution affects 
  the predictive distribution for the time until the next extreme event. 

bibliography: CTRMstats.bib

output: 
  rticles::springer_article: 
    fig_caption: yes

params:
  tail: 0.8
  n: 10000

preamble: |
  \usepackage{amssymb}
---

```{r get-rticles, eval=FALSE, include=FALSE, cache=TRUE}
# use this rticles version: 
devtools::install_github("rstudio/rticles")
# use the newest MittagLeffleR version:
devtools::install_github("UNSW-MATH/MittagLeffleR")
library(MittagLeffleR)
devtools::install_github("UNSW-MATH/CTRE")
library(CTRE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  fig.height = 3, out.width = '\\textwidth'
  )
library(CTRE)
library(MittagLeffleR)
library(magrittr)
```


# Introduction

Time series displaying temporally inhomogeneous behaviour have received 
strong interest in the recent statistical physics literature 
[@Barabasi2005; @Oliveira2005; @Vasquez2006; @Vazquez2007; @Omi2011; 
@Min2010; @Karsai2011; @Bagrow2013]. They have been observed in the context 
of earthquakes, sunspots, neuronal activity and human communication [see 
@Karsai2012; @Vajna2013; @MeerschaertStoev08 for a list of references]. 
Such time series exhibit high activity in some 'bursty' intervals, which 
alternate with other, quiet intervals.  Although several mechanisms are 
plausible explanations for bursty behaviour (most prominently self-exciting
point process by @hawkes1971point), there seems to be one salient feature 
which very typically indicates the departure from temporal homogeneity: a 
heavy-tailed distribution of waiting times [@Vasquez2006; @Karsai2012; 
@Vajna2013]. As we show below in simulations, a simple renewal process with
heavy-tailed waiting times can capture this type of dynamics. For many 
systems, the renewal property is appropriate; a simple test of the absence 
of correlations in a succession of waiting times can be undertaken by 
randomly reshuffling the waiting times [@Karsai2012].

Often a magnitude, or mark can be assigned to each event in the renewal process, 
such as for earthquakes, solar flares or neuron voltages. 
The Peaks-Over-Threshold model [POT, see e.g. @ColesBook] applies a
threshold to the magnitudes, and fits a Generalized Pareto distribution 
to the threshold exceedances. 
A commonly made assumption in POT models is that times between 
events are either fixed 
or light-tailed, and this entails that the 
threshold crossing times form a Poisson process [@Hsing88]. 
Then as one increases the threshold and thus decreases the threshold 
crossing probability $p$, the Poisson process is rarefied, i.e. its 
intensity decreases _linearly_ with $p$ [see e.g. @beirlantBook]. 

As will be shown below, in the heavy-tailed waiting time scenario threshold 
crossing times form a _fractional Poisson process_ 
[@Laskin2003; @Meerschaert2010b], which is a 
renewal process with Mittag-Leffler distributed waiting times. 
The family of Mittag-Leffler distributions nests the exponential 
distribution [@Haubold11], and hence the fractional Poisson process
generalizes the standard Poisson process. 
Again as the threshold size increases and the threshold crossing
probability $p$ decreases, the fractional Poisson process is rarefied: 
The scale parameter of the Mittag-Leffler inter-arrival times of 
threshold crossing times increases, but _superlinearly_; 
see the Theorem below.


Maxima of events which occur according to a renewal process with
heavy-tailed waiting times have been studied under 
the names "Continuous Time Random Maxima process" (CTRM) 
[@Benson2007; @MeerschaertStoev08; @Hees16; @Hees17], 
"Max-Renewal process" [@Silvestrov2002a; @ST04; @Basrak2014], 
and "Shock process"
[@Esary1973; @Sumita1983; @Sumita1984; @Sumita1985; @Anderson1987; @Gut1999].
The existing literature focuses on probabilistic results surrounding these 
models. 
In this work, however, we introduce a method of inference for this type of 
model, which is seemingly not available in the literature.

We review the marked renewal process in Section 2, and 
derive a scaling limit theorem for inter-exceedance times in Section 3.
We give a statistical procedure to estimate model parameters via stability plots 
in Section 5, but to set the stage we first discuss inference for the 
Mittag-Leffler distribution in Section 4. 
(A simulation study of the effectiveness of our statistical procedure is 
given in the appendix.)
Diagnostic plots for model criticism are discussed in Section 6. 
In Section 7, we discuss the memory property of the 
Mittag-Leffler distribution, and how it affects the predictive distribution 
for the time until the next threshold crossing event. 
Section 8 concludes. 
For all statistical computations we have used R [@R]. 
All code and data used for the analysis in this article has been organized into 
an R package `CTRE` (<https://github.com/UNSW-MATH/CTRE>).
The source code for the figures generated in this manuscript is 
available online at <https://github.com/UNSW-MATH/bursty-POT>. 


# Continuous Time Random Exceedances (CTRE)

As a model for extreme observations, we use a Marked Renewal Process (MRP):

**Definition (MRP):** 

: Let $(W,J), (W_1, J_1), (W_2, J_2), \ldots$ be i.i.d. pairs of random 
variables, where the $W_k > 0$ are interpreted as the *waiting times* 
and $J_k \in [x_L, x_R]$ as the *event magnitudes* 
($x_L \in [-\infty, +\infty), x_R \in (-\infty, +\infty]$). 
If $W$ and $J$ are independent, the Marked Renewal Process is said to be *uncoupled*. 
\qed

Note that the $k$-th magnitude $J_k$ occurs at time
$T_k = W_1 + \ldots + W_k$. 
Based on an MRP, we define the Continuous Time Random Exceedance model
(CTRE) as follows:

**Definition (CTRE):** 

: Given a threshold $\ell \in (x_L, x_R)$, 
consider the stopping time 
$$\tau(\ell) := \min\{k: J_k > \ell\},\quad \ell \in (x_L, x_R).$$
Define the pair of random variables $(X(\ell), T(\ell))$ via 
$$X(\ell) = J_{\tau(\ell)} - \ell, \quad 
T(\ell) = \sum_{k=1}^{\tau(\ell)} W_k.$$
By restarting the MRP at $\tau(\ell)$, inductively define the
two i.i.d. sequences $T(\ell,n)$ and $X(\ell, n)$, $n \in \mathbb N$, 
called the "interarrival times" and the "exceedances", respectively.
The pair sequence $(T(\ell, n), W(\ell, n))_{n \in \mathbb N}$ is called 
a Continuous Time Random Exceedance model (CTRE). 
If the underlying MRP is uncoupled, then the CTRE is also called 
uncoupled. 
\qed

```{r thresholdedBursty, message=FALSE, fig.height=7, fig.width=9, fig.cap="\\label{fig:thresholdedBursty}Exceedances (red) and Times until Exceedance (durations between blue crosses) for a given threshold $\\ell$ (dashed line)."}
tail <- params$tail
n <- params$n 
sigma <- (cos(pi*tail/2))^(1/tail)
times <- cumsum(stabledist::rstable(n, tail, 1, sigma, pm=1))
#times<-cumsum(rpareto(n,tail))
magnitudes <- extRemes::revd(n, scale = 1, shape = 0)
sim_ctre <- ctre(data.frame(times, magnitudes)) 
par(mfrow = c(2,1))
plot(sim_ctre, p = 0.01, main = "Simulated MRP") 
flares %>% ctre() %>% plot(p = 0.02, log = 'y', main = "HXRBS data") 
```

In this article, we restrict ourselves to the uncoupled case, where
the two sequences $X(\ell, n)_{n \in \mathbb N}$
and $T(\ell, n)_{n \in \mathbb N}$ are independent.[^1]
Figure \ref{fig:thresholdedBursty} shows a simulated dataset in the top 
panel, where $W$ has a stable distribution with tail parameter 
$\beta =$ `r params$tail` (and skewness $1$ and location $0$), and 
where $J$ is from a standard Gumbel distribution. In the bottom panel, 
we plot a time series of solar flare intensities derived from a NASA
dataset [@HXRBS][^*]. Clearly, the simulated data exhibit long intervals 
_without any_ events, whereas in the real-world dataset events appear 
continuously. The threshold exceedances, however, appear to have similar
statistical behaviour in both models. Observations below a threshold are 
commonly discarded in Extreme Value Theory (POT approach); likewise, the CTRE model
interprets these observations as noise and filters them out.

[^1]: To see why, note that $X(\ell)$ is, in distribution, simply equal to 
  $J | J > \ell$, independent of any waiting time $W_k$.

[^*]: The "complete Hard X Ray Burst Spectrometer event list" 
is a comprehensive reference for all measurements of the Hard X 
Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of 
launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,776 
events were detected, with the "vast 
majority being solar flares". The list includes the start time, peak time, 
duration, and peak rate of each event. We have used "start time" as the 
variable for event times, and "peak rate" as the variable for event 
magnitudes. 



# Scaling limit of Exceedance Times {#sec:scaling}

In this section we state and prove the key theorem, see below.
For an accessible introduction to regular variation and stable limit theorems, we 
recommend the book by @MeerschaertSikorskii. 

**Theorem:**  

: Let the waiting times $J_k$ be in the domain of attraction of a 
positively skewed sum-stable law with stability parameter $0 < \beta < 1$; 
more precisely,
\begin{align} \label{eq:stability}
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
for a function $b(n)$ which is regularly varying at $\infty$ with 
parameter $1/\beta$, and where $\mathbf E[\exp(-sD)] = \exp(-s^\beta)$. 
Write $p := \mathbf P(J > \ell)$. Then the weak convergence
$$
\frac{T(\ell)} {b(1/p)} \to W_\beta \quad \text{ as } \quad \ell \uparrow x_R
$$
holds, where the Mittag-Leffler random variable $W_\beta$ is defined on 
the positive real numbers via 
$$
\mathbf E[\exp(-sW_\beta)] = \frac{1}{1+s^\beta}.
$$
\qed


\noindent For a scale parameter $\sigma > 0$, we write 
${\rm ML}(\beta, \sigma)$ for the distribution of $\sigma W_\beta$. 
The Mittag-Leffler distribution with parameter $\beta \in (0,1]$ is 
a heavy-tailed positive distribution for $\beta < 1$, with infinite mean. 
However, as $\beta \uparrow 1$, ${\rm ML}(\beta, \sigma)$ converges 
weakly to the exponential distribution ${\rm Exp}(\sigma)$.
This means that although its moments are all infinite, the Mittag-Leffler
distribution may (if $\beta$ is close to 1) be indistinguishable from the 
exponential distribution, for the purposes of applied statistics. 
For a detailed reference on the Mittag-Leffler distribution, see e.g. 
@Haubold11, and for algorithms, see e.g. the R package `MittagLeffleR`
[@MittagLeffleR].

#### _Proof of Theorem:_
We interpret the threshold crossing time $T(\ell)$ as the hitting time of the 
underlying CTRM (Continuous Time Random Maxima) or "max-renewal process", 
and then utilize a result by @MeerschaertStoev08. 
The running maximum process is defined as 
$$
M(c) := J_1 \vee \ldots \vee J_{\lfloor c \rfloor},
$$
and since we assume that the $J_k$ have a continuous distribution, there exist 
norming functions $a(c)$ and $d(c)$ such that 
$$
\mathbf P\left[ \frac{M(c) - d(c)}{a(c)} \le \ell^* \right] 
\longrightarrow F(\ell^*), \quad t \to \infty
$$
where $F$ is a generalized extreme value distribution, and $\ell^*$ is any 
value from the support of $F$. 
The CTRM process is then defined via 
$$
V(t) = M(N(t)), \quad t \ge 0
$$
where $N(t)$ is the renewal process associated with the waiting times 
$W_k$: 
$$
N(t) = \max\{n: W_1 + \ldots + W_n \le t\}.
$$
Now a key observation is that
$$
T(\ell) = \inf\{t: V(t) > \ell\}, 
$$
and that 
$$
T(\ell) > t \quad \text{ if and only if } \quad V(t) \le \ell.
$$
By [Theorem 3.1, @MeerschaertStoev08], we have the stochastic process 
convergence 
$$
\frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\stackrel{d}{\longrightarrow} Y(t), \quad t > 0.
$$
where $Y(t)$ is a time-changed ("subordinated") extremal process, and where 
$\tilde b(c)$ is a regularly varying norming function which is
_inverse_ to $b(c)$, in the sense that 
$b(\tilde b(c)) \sim c \sim \tilde b(b(c))$. 

Without loss of generality, we choose $\ell^*$ such that $F(\ell^*) = 1/e$, 
and let $\ell = a(\tilde b(c)) \ell^* + d(\tilde b(c))$. 
We may then calculate 
$$
\mathbf P\left[ \frac{T(\ell)}{b(1/p)} > t \right]
= \mathbf P[T(\ell) > b(1/p) t]
= \mathbf P[V(ct) \le \ell]
$$
where we have substituted $c = b(1/p)$. Moreover 
$$
\mathbf P[V(ct) \le \ell]
= \mathbf P\left[ \frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\le \frac{\ell - d(\tilde b(c))}{a(\tilde b(c))} \right]
\longrightarrow \mathbf P\left[ Y(t) \le \ell^* \right]
$$
Defining the hitting time of level $\ell^*$ by $Y(t)$ as 
$\xi_{\ell^*} := \inf\{t: Y(t) > \ell^*\}$,
we then have 
$$
P\left[ Y(t) \le \ell^* \right] = \mathbf P[\xi_{\ell^*} > t] 
= \mathbf P[(-\log F(\ell^*))^{-1/\beta} X^{1/\beta} D > t]
$$
by [Proposition 4.2, @MeerschaertStoev08], where $X$ is an exponential 
random variable with mean $1$. 
Using [Theorem 19.1, @Haubold11], we see that 
$X^{1/\beta} D \sim {\rm ML}(\beta, 1)$, concluding the proof. 
\qed

**Remark:**
: If $\beta = 1$, the result of the Theorem above is standard, see e.g. 
Equation (2.2) in @Gut1999.

# Inference for the Mittag-Leffler distribution

```{r fig:QQ-plots, fig.cap="Pareto vs. Mittag-Leffler distribution, both with same tail exponent 0.8. Top row: solar flare magnitudes data, fitting nicely with a Pareto distribution. Bottom row: simulated Mittag-Leffler data. Left column: static QQ-Estimator plots, assessing a fit against the Pareto distribution. Centre column: dynamic QQ-Estimator plots. Right column: a usual QQ-Plot based on Mittag-Leffler quantiles.\\label{fig:QQ-plots}", fig.height=5.5, fig.width=7}
par(mfrow = c(2,3))

flare_mags <- flares %>% ctre() %>% thin(k=500) %>% magnitudes()
flares_exponent <- flare_mags %>% qqestplot_static()

flare_mags %>% tea::qqestplot(conf.int = TRUE)
abline(h = 0.8, lty = 2, col = 2)

flare_mags %>% mlqqplot(tail = 0.8, log = 'xy')
(flare_mags %>% MittagLeffleR::logMomentEstimator())[1:2] -> MLparams
flare_mags %>% qqline(distribution = function(p) qml(p, tail = 0.8, scale = MLparams[2]))

ML_data <- MittagLeffleR::rml(500, 0.8)
ML_exponent <- ML_data %>% qqestplot_static()

ML_exponent2 <- ML_data %>% tea::qqestplot(conf.int = TRUE)
abline(h=0.8, lty = 2, col = 2)

ML_data %>% mlqqplot(0.8, log = 'xy')
qqline(ML_data, distribution = function(p) qml(p, 0.8), col = 2)

```

Since the Mittag-Leffler distribution is heavy-tailed, many researchers 
would intuitively give the highest importance to the tail behaviour of the 
distribution, and 
estimate the exponent of the tail function with established methods such 
as the Hill estimator. The QQ-estimator [@Kratz96] is closely related to 
the Hill estimator and fits a 
least squares line through the logarithms of the ordered statistics 
(y-axis) and the corresponding quantiles of the exponential distribution 
(x-axis). The reciprocal slope is returned as the estimate of the tail 
exponent.
For instance, the top-left panel in Figure \ref{fig:QQ-plots} shows the 
(static) QQ-estimator for the magnitudes of the solar flare data, returning 
a good fit to a Pareto distribution with tail parameter 
`r round(flares_exponent, 2)`. The dynamic QQ-estimator plot (top-center panel)
plots the tail exponent estimate for the largest values at cutoffs 
varying up to the 5th order statistic, and the region of stability at 
0.8 indicates a recommended estimate.

However, as described nicely by @Resnick97, the less 
similar a heavy-tailed distribution is to a Pareto distribution, the less
useful a Hill or QQ-Plot estimator becomes. 
The bottom-left panel of Figure \ref{fig:QQ-plots}, for instance, shows the 
static QQ-estimator plot for $2000$ draws from the Mittag-Leffler distribution with 
tail parameter $0.8$. The stretched exponential shape means 
that the Mittag-Leffler distribution has more probability near $0$ than 
the Pareto distribution, severely biasing the estimator downwards 
(`r round(ML_exponent, 2)`). 
Even by looking at different cutoffs via the dynamic QQ-estimator plot 
(bottom-center panel) one hardly identifies $0.8$ as a clear candidate for 
a tail parameter estimate.

QQ-estimators, and the closely related Hill estimator, are hence not 
suitable to detect a heavy-tailed Mittag-Leffler distribution. Moreover, 
QQ-estimator plots of exponentially distributed data are virtually 
indistinguishable from the bottom-left panel. This shows that 
_Mittag-Leffler distributed data may look like exponentially distributed 
data if examined via a QQ-estimator_. 

```{r likelihood-ratio-test}
flares_arrivals <- flares %>% ctre() %>% thin(k = 500) %>% interarrival()
mlmle_out <- mlmle(data = flares_arrivals)
```

Hence if there is some prior expectation that the data are drawn from the 
Mittag-Leffler distribution
(as is the the case for threshold exceedance times),
then we recommend avoiding QQ-estimators and Hill plots altogether, 
and instead examining QQ-plots directly, on a logarithmic scale 
(see Figure \ref{fig:QQ-plots}, right column).
The scale parameter $\sigma$ is irrelevant for a QQ-Plot. 
The tail parameter $\beta$ can be estimated quickly via the log-moment 
method by @Cahoy2013, or via maximum likelihood. 
Both estimators are implemented in `MittagLeffleR` 
[@MittagLeffleR]. 
Since the exponential distribution is nested in the Mittag-Leffler 
family of distributions, a standard likelihood ratio test can be 
performed, with the exponential distribution as a null model against 
a Mittag-Leffler distribution as the alternative. 
As an example, the threshold crossing times for the solar flare dataset
(Figure \ref{fig:flare-diagnostics-2}, right panel)
yield a difference in deviance of 
$\approx$ `r round(2 * (mlmle_out$loglik - mlmle_out$null_loglik))`, 
which evaluates to a strongly significant $\chi^2_1$ test statistic 
(p-value = $10^{`r round(log10(mlmle_out$p_value))`}$) for the null
hypothesis $\beta = 1$. 





# Inference on Exceedance times

```{r solar-flare-tail-scale, message=FALSE, fig.height=4.5, fig.width=8, fig.cap="\\label{fig:flares}Stability plots for the tail and scale parameter of the Mittag-Leffler distribution of the Solar Flare dataset. Dotted horizontal lines are at $\\beta = 0.85$ and $\\sigma_0 = 3 \\times 10^7$ seconds $\\approx 0.95$ years."}
thin_flares_ctre <- flares %>% ctre() %>% thin(k = 700)
par(mfrow=c(1,2))
MLestimates(thin_flares_ctre, tail = 0.9, scale = 3 * 1E7)
```

The Theorem in Section \ref{sec:scaling} implies that for a high 
threshold $\ell$ we may 
approximate the distribution of $T(\ell)$ with an 
${\rm ML}(\beta, b(1/p))$ distribution, 
where $b(\,)$ varies regularly at $\infty$ with parameter $1/\beta$.
Building on the POT (Peaks Over Threshold) method, we propose the 
following estimation procedure for the distribution of $T(\ell)$: 

1. For a range of thresholds $\ell$ near the largest order statistics, 
  extract datasets of exceedance times $\{T(\ell, i)\}_i$.
  
2. For each choice of threshold $\ell$, 
  fit a Mittag-Leffler distribution to the resulting dataset
  $\{T(\ell, i)\}_i$. 
  This results in the estimates $\{\hat\beta(\ell)\}_\ell$ and 
  $\{\hat \sigma(\ell)\}_\ell$.
  

3. Plot $\ell$ vs.\ $\hat \beta(\ell)$. As $\ell$ increases towards $x_R$, 
  $\hat \beta(\ell)$ *stabilizes* around a constant $\hat \beta$. 
  Use $\hat \beta$ as an estimate for the tail parameter $\beta$ of the
  Mittag-Leffler distribution of exceedance times. 
  

4. Approximate $p \approx |\{k: J_k > \ell\}| / n$. 
  Recall that $b(c)$ is regularly varying with parameter $1/\beta$, and 
  hence has the representation $b(c) = L(c) c^{1/\beta}$ for some 
  slowly varying function $L(c)$. 
  Assuming that the variation of $L(c)$ is negligible, we hence 
  plot $\ell$ vs.\ $p^{1/\hat \beta} \hat \sigma(\ell)$. 
  Again as $\ell$ increases towards $x_R$, 
  $p^{1/\hat \beta} \hat \sigma(\ell)$ is expected to stabilize around a constant 
  $\hat \sigma_0$. 
  We then use $p^{-1/\hat \beta} \hat \sigma_0$ as an estimate of the scale 
  parameter of the Mittag-Leffler distribution of exceedance times for
  the level $\ell$. 

The above approach, though theoretically sound, benefits from the following
practical adjustments (compare with Figure \ref{fig:flares}):

* We choose $\ell$ from the order statistics, i.e. $\ell$ is the $k$-th
  largest of the observations $X_j$, where $k$ runs from 
  $k_\text{min}, k_\text{min} + 1, \ldots, k_\text{max}$. 
  The datasets are then of length $k-1$.
* We use $k$ rather than $\ell$ for the horizontal axis of our plots. 
* In Step 4, rather than plotting $p^{1/\hat \beta} \hat \sigma(\ell)$
  we plot $k^{1/\hat \beta} \hat \sigma(\ell)$. This changes 
  $\hat \sigma_0$ by the multiplicative constant $n^{1/\hat \beta}$, 
  but has the advantage that
  $\hat \sigma_0$ does not change if one pre-processes the data by 
  removing all observations below a certain threshold. 


The estimates $\hat \beta$ and $\hat \sigma_0$ give an estimate of the 
distribution of exceedance times, dependent on the threshold $\ell$:
\begin{align*}
T(\ell) \sim {\rm ML}(\hat \beta, k^{-1/\hat \beta} \hat \sigma_0).
\end{align*}
For quick estimates of the Mittag-Leffler parameters we have used 
the method of log-transformed moments by @Cahoy2013.
We have verified the validity of our estimation algorithm  via simulations, 
see the appendix. 


# Checking Model Assumptions 


```{r flare-diagnostics-1, fig.height=7, fig.cap="Diagnostic plots for the solar flare data: auto-correlation function.\\label{fig:flare-diagnostics-1}"}
flares_ctre <- flares %>% ctre() %>% thin(k = 150)
acf(flares_ctre)
```


```{r flare-diagnostics-2, fig.height=7, fig.cap="Diagnostic plots for the solar flare data: empirical copula and QQ Plot. \\label{fig:flare-diagnostics-2}"}
par(mfrow = c(2,2))
empcopula(flares_ctre)
flares_ctre %>% interarrival() %>% mlqqplot(log = 'xy', tail = 0.8, main = "Mittag-Leffler QQ Plot")
```

The CTRE model is based on three main assumptions, which are repeated 
below. For each assumption, we suggest one means of checking if it holds: 

i.i.d.:
: After removing the "noise observations" below the smallest threshold 
  $\ell_0$, the pair sequence $(T(\ell_0, i), X(\ell_0,i))$ is i.i.d. 
  An indication if this is true is given 
  by an auto-correlation plot for the logarithms (to ensure finite moments) 
  of the two time series.
  

Uncoupled:
: Each $T(\ell, i)$ is independent of each $X(\ell, i)$. We propose an empirical copula
  plot to check for any dependence. 
  
  

${\rm ML}(\beta, \sigma)$ distribution of $T(\ell, i)$:
: Apply a cutoff at the lowest threshold $\ell_0$, 
  extract the threshold crossing times, 
  and create a QQ Plot for the Mittag-Leffler distribution. 
  Use a log-Moment estimate of the tail parameter for the theoretical / population 
  quantiles of the plot.


Figures \ref{fig:flare-diagnostics-1} and \ref{fig:flare-diagnostics-2} 
show the diagnostic plots for a 
minimum threshold chosen at the 200th order statistic. 
There is some residual autocorrelation for the sequence of threshold 
exceedance times that is not accounted for by the CTRE model. 
The fit with a Mittag-Leffler distribution ($\beta = 0.8$) is good, 
though there are signs that the power-law tail tapers off for very large 
inter-threshold crossing times. 
There is no apparent dependence between threshold exceedance times and 
event magnitudes seen in the copula plot. 


# Predicting the time of the next threshold crossing

According to Figure \ref{fig:flares}, for a threshold $\ell$ at the $k$-th order 
statistic, the fitted threshold exceedance time distribution is 
$$
T_\ell \sim {\rm ML}(\beta, k^{1/\beta} \sigma_0), 
$$
where $\beta = 0.85$ and $\sigma_0 = 3.0 \times 10^7 {\rm sec}$. 
Unlike the exponential distribution, the Mittag-Leffler distribution is not 
memoryless, and the probability density of the time $t$ until the next threshold 
crossing will depend on the time $t_0$ elapsed since the last threshold crossing.
This density equals 
$$
p(t|\beta, \sigma_0, \ell, t_0) = \frac{f(t + t_0 | \beta, k^{1/\beta} \sigma_0)}{\mathbf P[T_\ell > t_0]}
$$
where $f(\,\cdot\, | \beta, k^{1/\beta} \sigma_0)$ is the probability density of 
${\rm ML}(\beta, k^{1/\beta} \sigma_0)$. 
The more time has passed without a threshold crossing, the more the probability 
distribution shifts towards larger values for the next crossing
(see Figure \ref{fig:hazard}, left panel). 
The hazard rate 
$$
h(t) = \frac{f(t| \beta, k^{1/\beta} \sigma_0))}{\int_t^\infty f(\tau| \beta, k^{1/\beta} \sigma_0))\,d\tau}
$$
represents the risk of a threshold crossing per unit time, and is a 
decreasing function for the Mittag-Leffler distribution. 
The closer $\beta$ is to $1$, the more the hazard rate mimics that of an 
exponential distribution (a constant function, see Figure \ref{fig:hazard}, 
right panel). 

```{r hazard, fig.height=7, fig.cap="Left: Conditional distribution of time until next threshold crossing, depending on elapsed time $t_0$ since last crossing ($\\beta = 0.8$, $\\sigma_0 = 1$). Right: Hazard rate depending on tail parameter $\\beta$.\\label{fig:hazard}"}
tail <- 0.7
scale <- 1
t_0 <- c(0, 1, 10)
from <- 0.1
to <- 100 * scale
xx <- exp(seq(from = log(from), to = log(to), length.out = 100))
par(mfrow = c(2,2))
plot(xx, rep(1, length(xx)), ylim = c(0.001,1), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'p')
for (k in 1:length(t_0)) {
  cond <- pml(q = t_0[k], tail = tail, scale = scale, lower.tail = FALSE)
  yy <- dml(x = xx + t_0[k], tail = tail, scale = scale) / cond
  lines(xx,yy, col = k+1, lty = k)
}
legend("bottomleft", c("t_0 = 0", "t_0 = 1", "t_0 = 10"), col = 2:4, lty = 1:3)

betas <- c(0.7, 0.8, 0.95, 0.99)
t_0 <- 1
plot(xx, rep(1, length(xx)), ylim = c(0.001,2), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'h')
for (k in 1:length(betas)) {
  yy <- dml(x = xx, tail = betas[k], scale = scale) / pml(
    q = xx,
    tail = betas[k],
    scale = scale,
    lower.tail = FALSE
  )
  lines(xx,yy, col = k+1, lty = k)
}
legend("bottomleft", c("beta = 0.7", "beta = 0.8", "beta = 0.95", "beta = 0.99"), col = 2:5, lty = 1:4)

```

It is beyond the scope of the current paper to incorporate parameter 
uncertainty into our predictive distribution for the next threshold crossing; 
however, methods as described by @Scarrott12 and @Lee15 are likely 
to extend to our setting. 



# Discussion & Conclusion

We have extended the POT (Peaks over Threshold) model, a mainstay of 
extreme value theory, to "bursty" time series, which have been studied 
intensively in statistical physics. 
Burstiness is characterized by power-law waiting times between events, 
and we have shown that the Mittag-Leffler distribution arises naturally 
as a scaling limit for the inter-exceedance times of high thresholds. 
Moreover, we have derived the following non-linear scaling behaviour: 
$\sigma \sim p^{-1/\beta}$, 
where $\sigma$ is the scale parameter of the distribution of threshold 
exceedance times, 
$p$ is the fraction of magnitudes above the threshold, 
and $\beta$ the exponent of the power law. 


The "anomalous" scaling behaviour in the bursty setting entails two 
phenomena: 
i) a heavy tail of the interarrival time distribution of 
threshold crossings (long rests), and 
ii) a high propensity for more threshold crossing events immediately after 
each threshold crossing event (bursts). 
The Mittag-Leffler distribution captures both phenomena, due to its heavy
tail as well as its stretched exponential (peaked) asymptotics for small 
times. 
It generalizes the exponential distribution, and 
in the solar flare data example, this generalization 
is warranted, because the likelihood-ratio test is strongly significant. 


When we introduced the CTRE model, we assumed that all events are i.i.d. 
This assumption is likely sufficient but not necessary for our limit theorem to hold. 
Moreover, any data below a (minimum) threshold $\ell_0$ is discarded in 
our inference procedure, and hence need not satisfy the i.i.d. assumption.
For the purposes of statistical inference, we merely require that the 
inter-threshold-crossing times are i.i.d. However, it might be interesting 
to generalize our theory to the case of a stationary sequence of magnitudes. In case of fixed times between observations, the distribution of the sequence of (correctly normalized) inter-exceedance times converges under certain (mixing) conditions to a mixture of an exponential distribution and a point mass in zero [@ferro2003inference]. Hence, this also leads to a model for extreme events that occur in cluster. Allowing for both, dependence between the magnitudes and heavy tailed waiting times, could maybe further improve modelling of extreme events like earthquakes, that occur in clusters.  


For some bursty time series, the current CTRE model may be too rigid, 
because often the heavy-tailed character of the inter-arrival time
distribution does not hold at all time scales; rather, it often applies at 
short and intermediate time scales, and is truncated or tempered 
(reverting to an exponential distribution) at 
very long time scales, see e.g. @MeerschaertRoyQin and @Aban06. 
In such situations, a "tempered" Mittag-Leffler distribution may provide 
a more realistic fit, which we aim to introduce in follow-up work. 


## Acknowledgements {-}

The authors would like to thank Prof. Peter Scheffler for insights on 
stochastic process limits for CTRMs, and Gurtek Gill who helped create
the MittagLeffleR R-package. 

\appendix


# Validating our inference method on simulated data

To test our inference method via stability plots, we have simulated `r params$n` 
independent
waiting time and magnitude pairs $(W_k, J_k)$ (see upper panel in 
Figure \ref{fig:thresholdedBursty}). In order to have exact 
analytical values available for $\beta$ and $\sigma_0$, a distribution for 
$W_k$ needs to be chosen for which $b(n)$ from \eqref{eq:stability} is known. 
If we choose $W_k \stackrel{d}{=} D$, where $D$ is as in \eqref{eq:stability}, 
then due to the stability property we have the *equality* of distribution
$W_1 + \ldots + W_n \stackrel{d}{=} b(n) D$, 
for $b(n) = n^{1/\beta}$. 
Using the parametrisation of @SamorodnitskyTaqqu, a few lines of 
calculation (see e.g. the vignette on parametrisation in @MittagLeffleR) 
show that $D$ must have the stable distribution 
$S_\beta(\cos(\pi \beta/2)^{1/\beta}, +1, 0)$, which is 
implemented in the R package `stabledist` by @stabledist. 

```{r make-caption}
caption = "Tail and scale estimates for simulated data, with waiting times drawn from the stable distribution $S_\\beta(\\cos(\\pi \\beta/2)^{1/\\beta}, +1, 0)$ with $\\beta = 0.8$. Dashed lines are 95\\% confidence intervals, dotted lines are the known theoretical values ($0.8$ and $10000^{1/0.8}$). \\label{fig:sim}"
```


```{r simulated-example, message=FALSE, fig.cap=caption}
k_max <- 500 
thin_sim_ctre <- thin(ctre = sim_ctre, k = k_max)
par(mfrow=c(1,2))
MLestimates(ctre = thin_sim_ctre, tail = params$tail, scale = n^(1/params$tail))
```

By the Theorem, the distribution 
of $T(\ell)$ is approximately 
$$
{\rm ML}(\beta, p^{-1/\beta}) 
= {\rm ML}(\beta, k^{-1/\beta} n^{1/\beta}),
$$
which means 
$\sigma_0 = n^{1/\beta}$.
The distribution of $J_k$ is irrelevant for the inference on $\beta$ and 
$\sigma_0$ (we have chosen unit exponential random variables). 
Figure \ref{fig:sim} displays plots of $\hat \beta(\ell)$ and 
$\hat \sigma(\ell)$ vs. $k$; recall that $k$ is the index of the order
statistics of $J_k$ at which the threshold $\ell$ is placed. 
Dotted lines show 95% confidence intervals, which are derived from the 
asymptotic normality of the log-moments estimators [@Cahoy2013] and the $\delta$-method [@MittagLeffleR].
The dashed lines show the actual values of $\beta$ resp.\ $\sigma_0$, 
showing that our inference method identifies the 
parameters correctly. 

# References {-}

